{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada (MNA)**\n",
        "##**Procesamiento de Lenguaje Natural (NLP)**\n",
        "###Prof. Luis Eduardo Falcón Morales\n",
        "###**Semana 4 - Ejercicios Complementarios**\n",
        "### Matriz Documento-Término y Tf-idf.\n",
        "\n",
        "###**NOTA: Estos ejercicios son simplemente para que repases los conceptos de esta semana.**\n",
        "###**No es una tarea o actividad que debas entregar.**"
      ],
      "metadata": {
        "id": "QjJeSftN02Th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comentamos que los diccionarios son una parte importante que permiten asociar a cada token su freuencia de aparición en los documentos de texto.\n",
        "\n",
        "Sin embargo, esto no es suficiente para medir la importancia y sobre todo, para asociar algún significado al token con base a los demás tokens que se utilizan en una frase o documento.\n",
        "\n",
        "Para ello, existen la matriz llamada documento-término y la matriz tf-idf.\n",
        "\n",
        "La matriz documento-término (abreviada DTM pos sus siglas en inglés, Documen-Term-Matrix) es una matriz donde cada renglón representa un documento o enunciado y cada columna son los términos o tokens.\n",
        "\n",
        "A partir de dicha matriz se puede obtener a su vez la llamada matriz término-frecuencia y frecuencia de documento inversa. En general se le llama por sus siglas en inglés tf-idf, term-frequency-inverse-document-frequency. \n",
        "\n",
        "La matriz tf-idf trata de obtener una representación de los tokens y los documentos, donde pondera la aparición de los tokens como importantes cuando aparece con frecuencia; pero no demasiado, porque si aparece demasiado castiga a dicho token disminuyendo su peso. Es decir, es algo análogo al concepto de los stopwords, donde un token muestra su importancia cuando aparece frecuentemente, pero no demasiado frecuente porque entonces se hace trivial su aparición.\n",
        "\n",
        "Veamos estos conceptos con un ejercicio."
      ],
      "metadata": {
        "id": "bDkdMJpSEqyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retomemos el ejercicio de la semana pasada.\n",
        "\n",
        "Recordemos que estamos suponiendo que tenemos la siguiente lista de comentarios en un problema de clasificación, donde cada uno está etiquetado como comentario positivo con un 1, o como comentario negativo con un 0."
      ],
      "metadata": {
        "id": "uBEFNGuV7369"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "IwLeUqGZE7ii"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [['Muy bien hecho lo hecho.', 1],\n",
        "        ['¡Excelente trabajo muchacho!', 1],\n",
        "        ['Sigue como hasta ahora muchacho.', 1],\n",
        "        ['Lo hiciste muy bien.', 1],\n",
        "        ['¡¡Excelente resultado!!', 1],\n",
        "        ['¡¡¡Pésimo trabajo muchacho!!!', 0],\n",
        "        ['Que mal desempeño.', 0],\n",
        "        ['Muy mal hecho muchacho.', 0],\n",
        "        ['¡Que trabajo tan pobre!', 0],\n",
        "        ['No está bien, nada bien, muchacho.', 0]]"
      ],
      "metadata": {
        "id": "AVTO4V9s7Fek"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apliquemos el proceso de limpieza y tokenización usual:"
      ],
      "metadata": {
        "id": "htyrLDkSZ_rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xclean = []  \n",
        "mis_stopwords = ['a', 'lo', 'que', 'está', 'hasta', 'el', 'la']\n",
        "\n",
        "for doc in docs:\n",
        "  words = re.sub(r'[^a-zA-ZáéíóúüñÁÉÍÓÚÜÑ]', ' ', doc[0])   \n",
        "  words = re.sub(r'\\s{2,}', ' ', words.strip())      \n",
        "  words = words.lower().split()\n",
        "  words = [ w for w in words if w not in mis_stopwords]\n",
        "  Xclean.append(words)\n",
        "\n",
        "\n",
        "Xx = []  \n",
        "for x in Xclean:\n",
        "  Xx.append(' '.join(x))\n",
        "\n",
        "\n",
        "y = [t for _,t in docs]\n",
        "\n",
        "\n",
        "\n",
        "# Xclean : lista de listas: documentos tokenizados y procesados.\n",
        "# Xx : lista de strings: cada documento es un string.\n",
        "# y : etiquetas de cada documento."
      ],
      "metadata": {
        "id": "6tkgQ4m7E-_5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xclean)\n",
        "print(Xx)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMVB1siThMZP",
        "outputId": "30f8edd9-4413-486f-c5c8-36e7be6553c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['muy', 'bien', 'hecho', 'hecho'], ['excelente', 'trabajo', 'muchacho'], ['sigue', 'como', 'ahora', 'muchacho'], ['hiciste', 'muy', 'bien'], ['excelente', 'resultado'], ['pésimo', 'trabajo', 'muchacho'], ['mal', 'desempeño'], ['muy', 'mal', 'hecho', 'muchacho'], ['trabajo', 'tan', 'pobre'], ['no', 'bien', 'nada', 'bien', 'muchacho']]\n",
            "['muy bien hecho hecho', 'excelente trabajo muchacho', 'sigue como ahora muchacho', 'hiciste muy bien', 'excelente resultado', 'pésimo trabajo muchacho', 'mal desempeño', 'muy mal hecho muchacho', 'trabajo tan pobre', 'no bien nada bien muchacho']\n",
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NaoxpdL4Gl1W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos nuestro vocabulario:\n",
        "\n",
        "vocab = []\n",
        "for x in Xclean:     \n",
        "  vocab.extend(x)    \n",
        "  vocab = list(set(vocab))\n",
        "\n",
        "vocab.sort()  \n",
        "\n",
        "print(len(vocab))\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFHLLYskGKCG",
        "outputId": "665a8332-3ecc-49d7-a4fc-a8986c654271"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "['ahora', 'bien', 'como', 'desempeño', 'excelente', 'hecho', 'hiciste', 'mal', 'muchacho', 'muy', 'nada', 'no', 'pobre', 'pésimo', 'resultado', 'sigue', 'tan', 'trabajo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así, con 18 tokens se deberá procesar y analizar los documentos."
      ],
      "metadata": {
        "id": "eG9Gyz8kkZn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Matriz Documento-Término: Document-Term-Matrix : DTM**"
      ],
      "metadata": {
        "id": "bkdiOw9Li9fM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Comentamos que existe una gran variedad de librerías para obtener las diferentes representaciones matriciales de los documentos de texto.\n",
        "\n",
        "###En particular, haciendo uso de CountVectorizer() de sklearn, podemos obtener la matriz DTM. \n",
        "\n",
        "###Si generaste tu vocabulario puedes usarlo para generar las matrices, de lo contrario puedes dejar que el propio método lo genere. Sin embargo, conviene trabajarlo uno personalmente, sobre todo por lo realizado con regex.\n",
        "\n",
        "Veamos este caso sencillo:"
      ],
      "metadata": {
        "id": "T5wQY-__klMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "lWTlxJt5k6_m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(vocabulary= vocab)  \n",
        "\n",
        "DTM = vectorizer.fit_transform(Xx)\n",
        "\n",
        "print('matriz DTM:')\n",
        "print(DTM.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47CxGR58Tjeg",
        "outputId": "fed48b9c-a04a-48ad-85aa-76fe9c821757"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matriz DTM:\n",
            "[[0 1 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
            " [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            " [0 2 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Podemos asociar el nombre de cada columna/token del vocabulario para mayor claridad, por ejemplo, nuevamente para el primer comentario:"
      ],
      "metadata": {
        "id": "dXTlnpPdwpN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens = vectorizer.get_feature_names_out()\n",
        "df_countvect = pd.DataFrame(data = DTM.toarray(),  columns = count_tokens)  \n",
        "print(df_countvect.iloc[0:1,0:]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXVEZlZJFpqP",
        "outputId": "6e8b8cab-4222-42f7-a361-c3e025781ef7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ahora  bien  como  desempeño  excelente  hecho  hiciste  mal  muchacho  \\\n",
            "0      0     1     0          0          0      2        0    0         0   \n",
            "\n",
            "   muy  nada  no  pobre  pésimo  resultado  sigue  tan  trabajo  \n",
            "0    1     0   0      0       0          0      0    0        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###La dimensión de esta document-term-matrix, DTM, es $(renglones\\times columnas)=(Total De Comentarios \\times Total De Tokens)$. Es decir, $10\\times 18$ en nuestro ejemplo.\n",
        "\n",
        "###Por ejemplo, el primer comentario es 'muy bien hecho hecho' y los índices de los tokens 'muy', 'bien' y 'hecho' son 9, 1 y 5. Y como 'hecho' aparece 2 veces en el primer comentario su vector asociado es como se muestra en el primer renglón de la matriz DTM.\n",
        "\n",
        "###Por otro lado, obervamos que la matriz DTM tiene una gran cantidad de ceros. En general así sucede, porque cada comentario hace uso de una cantidad mínima de palabras del vocabulario. Este tipo de matrices son llamadas dispersas (sparse matrix).\n",
        "\n",
        "###De manera predeterminada CountVectorizer() nos regresa una matriz dispersa. En este ejemplo hicimos uso del método \"toarray()\" para mostrar la matriz en su formato estándar. Sin embargo, esto no debes hacerlo en general, ya que son matrices muy muy grandes y tratar de visualizarlas de la manera estándar puede hacer uso de toda la memoria RAM.\n",
        "\n",
        "###En particular, el formato predeterminado del tipo de matriz dispersa es la CSR (Compressed-Sparse-Row, por sus siglas en inglés).\n",
        "\n",
        "###Lo podemos verificar:"
      ],
      "metadata": {
        "id": "uP24pUnIloxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DTM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiYekNzeuArS",
        "outputId": "4f6e02bf-cee0-4569-ddd0-c3257c880ef5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<10x18 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 31 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos 31 elementos no cero, de un total de 180 entradas de la matriz.\n",
        "\n",
        "Es decir:"
      ],
      "metadata": {
        "id": "eV4iyZpmvEuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DTM.count_nonzero() / (DTM.shape[0] * DTM.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI9ALS0sui2O",
        "outputId": "6c33b186-6292-4f6a-c4f5-ed642a38259b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es decir, en este pequeño ejemplo el 17% de los registros son no cero y el 83% son entradas de valor cero. Así, diremos que la matriz DTM tiene una dsipersidad (sparsity en inglés) del 83%. \n",
        "\n",
        "En la práctica, es usual que la dispersidad de las matrices DTM esté muy por arriba del 95%. Por ello la conveniencia de utilizar este tipo de formatos dispersos."
      ],
      "metadata": {
        "id": "r7DuQEvXv2fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Matriz Tf-idf**"
      ],
      "metadata": {
        "id": "jDuqgrpGq_MC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comentamos en las diapositivas de la teoría de esta semana, la matriz Tf-idf pondera cada token por frecuencia de aparición, pero si aparece \"demasiadas\" veces, se le penaliza disminuyendo su peso."
      ],
      "metadata": {
        "id": "cBvr6XhgrMW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfvectorizer = TfidfVectorizer(vocabulary=vocab, norm=None)\n",
        "DTM_train_tfidf = tfidfvectorizer.fit_transform(Xx)   "
      ],
      "metadata": {
        "id": "MsKYiMydFpi3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_tokens = tfidfvectorizer.get_feature_names_out()\n",
        "df_tfidfvect = pd.DataFrame(data = DTM_train_tfidf.toarray(),  columns = tfidf_tokens)  \n",
        "print(df_tfidfvect.iloc[0:1,0:]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1esgipqFpag",
        "outputId": "762faf04-6854-4468-fbbe-0eb82d795b2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ahora      bien  como  desempeño  excelente     hecho  hiciste  mal  \\\n",
            "0    0.0  2.011601   0.0        0.0        0.0  4.598566      0.0  0.0   \n",
            "\n",
            "   muchacho       muy  nada   no  pobre  pésimo  resultado  sigue  tan  \\\n",
            "0       0.0  2.011601   0.0  0.0    0.0     0.0        0.0    0.0  0.0   \n",
            "\n",
            "   trabajo  \n",
            "0      0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este primer comentario vemos que la palabra \"hecho\" es la considerada que da mayor información con el mayor valor. Y su importancia en este comentario se justifica por aparecer dos veces en este. A los tokens \"bien\" y \"muy\" los poderó de manera igual, que en este caso ambos tokens aparecen una sola vez.\n",
        "\n",
        "En la preentación de este semana definimos de manera detallada las fórmulas para calcular el valor de $tf\\times idf$.\n",
        "\n",
        "Sin embargo, existen muchas variantes en la manera en que se definen estos términos, en particular la $idf$. En general, las variaciones llegan a ser diversas, pero todas nos llevan en general a resultados muy equivalentes cuando usamos esta información con modelos de aprendizaje de máquinas.\n",
        "\n",
        "Se se revisa la documentación de TfidfVectorizer() vemos la manera en que calcula dichos valores.\n",
        "\n",
        "Puedes revisar la documentación en las siguientes dos ligas:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
        "\n"
      ],
      "metadata": {
        "id": "wU2BQbbWxTIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En particular, la fórmula que utiliza TfidfVectorizer() con el argumento \"norm=None\" que usamos arriba, es como sigue. Calculando el valor para el primer comentario y el token \"hecho\".\n",
        "\n",
        "$tf\\times idf = tf\\times ln(\\frac{D+1}{n_t+1})=2\\times \\{ln(\\frac{10+1}{2+1})+1\\}=4.598566$.\n",
        "\n",
        "Que es el resultado que se muestra en la salida que mostramos más arriba.\n"
      ],
      "metadata": {
        "id": "rv0nTCZKKMCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo importante es que estos valores de las matrices DTM y DTM_tfidf obtenidas con un conjunto de entrenamiento, pueden utilizarse para entrenar un modelo y después validarlo con los conjuntos de validación y de prueba."
      ],
      "metadata": {
        "id": "udZxspGLMhF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A manera de ejemplo, supongamos que deseamos aplicar estos modelos con regresión logística."
      ],
      "metadata": {
        "id": "MbJ9UbC9NUN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "sjNL4lpXNeSu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloCount = LogisticRegression(max_iter=100, C=1.)\n",
        "modeloCount.fit(DTM, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "15prjvmpNqSM",
        "outputId": "d43d38ce-76d5-41d0-b949-826b4fd17971"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nModelo Counter con regresión Logística: Train-accuracy: %.2f%%' % (100*modeloCount.score(DTM, y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgy98kalOgS9",
        "outputId": "09b3e677-9385-419b-ddbd-864dc5fc2728"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo Counter con regresión Logística: Train-accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y de manera análoga con la matriz Tf-idf:"
      ],
      "metadata": {
        "id": "l4-CLJlhOthu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modeloTfidf = LogisticRegression(max_iter=100, C=1.)\n",
        "modeloTfidf.fit(DTM_train_tfidf, y)\n",
        "print('\\nModelo Tfidf con Regresión Logística: Train-accuracy: %.2f%%' % (100*modeloTfidf.score(DTM_train_tfidf, y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5SSwiQPOyQ4",
        "outputId": "700053fb-7bc1-4873-9a71-660ed07e176f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo Tfidf con Regresión Logística: Train-accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobra decir que este modelo esta sobre-entrenado porque solo estamos usando un mismo conjunto para entrenar y validar, pero es solo a manera de ejemplo. Cuando se tenga el conjunto de validación y de prueba deberás hacer la validación de manera adecuada."
      ],
      "metadata": {
        "id": "w8Eqj5nmPTkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Fin de la Parte 2 de los ejercicios complementarios de la Semana 3**"
      ],
      "metadata": {
        "id": "2K7B5NYqKIK2"
      }
    }
  ]
}