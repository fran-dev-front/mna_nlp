{"cells":[{"cell_type":"markdown","id":"daba65bd","metadata":{"id":"daba65bd"},"source":["# **Maestr√≠a en Inteligencia Artificial Aplicada**\n","\n","## Curso: **Procesamiento de Lenguaje Natural**\n","\n","### Tecnol√≥gico de Monterrey\n","\n","### Prof Luis Eduardo Falc√≥n Morales\n","\n","## Adtividad Semana 9\n","\n","### **Modelos Transformer & LLM**"]},{"cell_type":"markdown","id":"e36d66c9","metadata":{"id":"e36d66c9"},"source":["#### **Nombres y matr√≠culas de los integrantes del equipo:**\n","\n","\n","\n","*   Salvador Mart√≠nez - A01273366\n","*   Miguel Angel Marines Olvera - A01705317\n"]},{"cell_type":"markdown","id":"481a83f8","metadata":{"id":"481a83f8"},"source":["### En la actividad de esta semana trabajar√°s en equipos mediante el uso de Transformers en combinaci√≥n con LLMs."]},{"cell_type":"markdown","id":"be9c784e","metadata":{"id":"be9c784e"},"source":["Nos apoyaremos en la plataforma de HuggingFace (HF): https://huggingface.co/\n","\n","La plataforma de HF est√° muy bien documentada, es de acceso abierto, pero deber√°s generar una cuenta sin costo para su uso. En ocasiones deber√°s generar una clave para el uso de algunos modelos; pero es solo para el control del uso de dicha plataforma y no genera alg√∫n costo para su uso educativo o de investigaci√≥n, ni tampoco se requiere introducir una tarjeta de cr√©dito, al menos hasta ahora.\n","\n","En particular en esta actividad usaremos algunos modelos Transformer y de LLM. El objetivo principal es que te familiarices con ambas t√©cnicas y puedas empezar a ver sus ventajas y desventajas para futuros proyectos en los cuales desees implementarlos.\n","\n","En particular puedes apoyarte en el siguiente tutorial de la misma comunidad de HF para llevar a cabo la preparaci√≥n, tokenizaci√≥n y entrenamiento del modelo en tu JupyterNotebook:\n","https://huggingface.co/blog/sentiment-analysis-python"]},{"cell_type":"code","execution_count":1,"id":"Ye_sKVk69eGf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22427,"status":"ok","timestamp":1718639998705,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"Ye_sKVk69eGf","outputId":"1ffb5fa2-7de9-4232-8686-54119dd9de19"},"outputs":[],"source":["# Google Drive en Google Colab.\n","# Acceso a los archivos y directorios almacenados en Google Drive desde un notebook de Colab.\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","# Manejo DataFrames.\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"8hNGKxZa-7hp","metadata":{"executionInfo":{"elapsed":220,"status":"ok","timestamp":1718640029157,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"8hNGKxZa-7hp"},"outputs":[],"source":["# Manejo DataFrames.\n","import pandas as pd"]},{"cell_type":"code","execution_count":34,"id":"a92e5d98","metadata":{"executionInfo":{"elapsed":13217,"status":"ok","timestamp":1718640049941,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"a92e5d98"},"outputs":[],"source":["# Librer√≠as\n","import torch\n","import numpy as np\n","import pandas as pd\n","from datasets import load_metric\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from transformers import TrainingArguments, Trainer\n","from transformers import DistilBertForSequenceClassification\n","from transformers import DataCollatorWithPadding\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","id":"7ee4e86b","metadata":{"id":"7ee4e86b"},"source":["#### 1.- Descarga el archivo amazonbaby5000.csv que se encuentra en Canvas. Este archivo est√° formado de 5 mil comentarios en ingl√©s sobre productos para beb√© adquiridos a trav√©s de la plataforma de Amazon."]},{"cell_type":"code","execution_count":4,"id":"1d415683","metadata":{"executionInfo":{"elapsed":795,"status":"ok","timestamp":1718640058321,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"1d415683"},"outputs":[],"source":["df = pd.read_csv('amazonbaby5000.csv')     # Carga de datos."]},{"cell_type":"code","execution_count":5,"id":"Et9LevJa_wnZ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1718640060713,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"Et9LevJa_wnZ","outputId":"70b2aa86-0353-49fb-d4a1-d04eeeb35018"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(df) == 5000   # Verificar que el conjunto de datos tenga la longitud de 5000 registrtos."]},{"cell_type":"code","execution_count":6,"id":"dd92528a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1718640063474,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"dd92528a","outputId":"301ac4d9-0de9-4c90-b03e-c1f49211ade7"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              review  rating\n","0  I think it is more Expensive than drugstore th...       0\n","1  When I saw this on Amazon, I put it into my wi...       1\n","2  We really like these valances.  They have such...       1\n","3  No light emits from the night light. They pain...       0\n","4  I was really hoping for this to be a conventie...       0\n"]}],"source":["print(df.head())     # Primeros 5 registros del conjunto de datos."]},{"cell_type":"code","execution_count":7,"id":"qpgRoa40_ggv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1718640066360,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"qpgRoa40_ggv","outputId":"8fd03eda-5289-40d3-a341-e0ade590d71c"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                 review  rating\n","4995  I like that this carrier is like the Moby in h...       1\n","4996  The box was damaged upon arrival. I was afraid...       1\n","4997  Purchased for graduation. Rec'd in 2 days like...       1\n","4998  For all of the reviews that said this car seat...       0\n","4999  I bought this thinking it would make my life a...       1\n"]}],"source":["print(df.tail())     # √öltimos 5 registros del conjunto de datos."]},{"cell_type":"code","execution_count":8,"id":"ec72a9e5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1718640068795,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"ec72a9e5","outputId":"eb81a3f5-a55b-47fc-b39e-44e2d27ee567"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5000 entries, 0 to 4999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   review  5000 non-null   object\n"," 1   rating  5000 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 78.3+ KB\n","None\n"]}],"source":["print(df.info())     # Informaci√≥n general del conjunto de datos."]},{"cell_type":"code","execution_count":9,"id":"uN3AsCkxAGBt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1718640071555,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"uN3AsCkxAGBt","outputId":"ef1d3830-8d26-428c-dc95-358ea996ba55"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                 review  rating\n","0     I think it is more Expensive than drugstore th...       0\n","1     When I saw this on Amazon, I put it into my wi...       1\n","2     We really like these valances.  They have such...       1\n","3     No light emits from the night light. They pain...       0\n","4     I was really hoping for this to be a conventie...       0\n","...                                                 ...     ...\n","4995  I like that this carrier is like the Moby in h...       1\n","4996  The box was damaged upon arrival. I was afraid...       1\n","4997  Purchased for graduation. Rec'd in 2 days like...       1\n","4998  For all of the reviews that said this car seat...       0\n","4999  I bought this thinking it would make my life a...       1\n","\n","[5000 rows x 2 columns]\n"]}],"source":["print(df)   # Mostrar el conjunto de datos."]},{"cell_type":"code","execution_count":10,"id":"34f7c0de","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":245,"status":"ok","timestamp":1718640076184,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"34f7c0de","outputId":"18fddfca-177d-45e8-98aa-95fdf485378b"},"outputs":[{"name":"stdout","output_type":"stream","text":["            rating\n","count  5000.000000\n","mean      0.768000\n","std       0.422151\n","min       0.000000\n","25%       1.000000\n","50%       1.000000\n","75%       1.000000\n","max       1.000000\n"]}],"source":["print(df.describe())     # Estad√≠sticas descriptivas del conjunto de datos."]},{"cell_type":"markdown","id":"3b724e16","metadata":{"id":"3b724e16"},"source":["#### 2.- Realiza una partici√≥n de los datos en el porcentaje que consideres adecuado, en entrenamiento y prueba."]},{"cell_type":"code","execution_count":11,"id":"f514ac3f","metadata":{"id":"f514ac3f","outputId":"1ba65bc1-ba93-42fb-bcce-05beebdd8f31"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mitnik/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n"]},{"data":{"text/plain":["False"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()     # Verificar si hay una GPU compatible con CUDA en el entorno."]},{"cell_type":"code","execution_count":12,"id":"d46b604a","metadata":{"id":"d46b604a","outputId":"874f7f7a-76d3-4d1b-ab24-2914ac22a56c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Versi√≥n de PyTorch: 2.3.0+cu121\n","Versi√≥n de CUDA soportada por PyTorch: 12.1\n","CUDA disponible: False\n","N√∫mero de GPUs disponibles: 1\n"]}],"source":["# Informar sobre la configuraci√≥n de PyTorch y la disponibilidad de CUDA en el sistema.\n","print(\"Versi√≥n de PyTorch:\", torch.__version__)\n","print(\"Versi√≥n de CUDA soportada por PyTorch:\", torch.version.cuda)\n","print(\"CUDA disponible:\", torch.cuda.is_available())\n","print(\"N√∫mero de GPUs disponibles:\", torch.cuda.device_count())"]},{"cell_type":"code","execution_count":13,"id":"82997b45","metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1718640089597,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"82997b45"},"outputs":[],"source":["# Se divide el conjunto de datos en 70% para entrenamiento y 30% para prueba.\n","train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":14,"id":"c5544176","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1718640092743,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"c5544176","outputId":"83aad128-d319-4464-c655-c01eebfab62a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tama√±o del conjunto de entrenamiento: 3500\n","Tama√±o del conjunto de prueba: 1500\n"]}],"source":["# Tama√±o de los conjuntos de entrenamiento y prueba.\n","print(f'Tama√±o del conjunto de entrenamiento: {train_df.shape[0]}')\n","print(f'Tama√±o del conjunto de prueba: {test_df.shape[0]}')"]},{"cell_type":"code","execution_count":15,"id":"KnciKwLw4qOj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1718640096359,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"KnciKwLw4qOj","outputId":"2b2f8531-c98c-4551-cea0-731282fb62fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 3500 entries, 1840 to 860\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   review  3500 non-null   object\n"," 1   rating  3500 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 82.0+ KB\n"]}],"source":["train_df.info()   # Verificar informaci√≥n de los datos de entrenamiento."]},{"cell_type":"code","execution_count":16,"id":"DxdATBRV40AG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1718640099428,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"DxdATBRV40AG","outputId":"e45f8a7d-608c-4635-c92e-700d258072a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1500 entries, 1501 to 1912\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   review  1500 non-null   object\n"," 1   rating  1500 non-null   int64 \n","dtypes: int64(1), object(1)\n","memory usage: 35.2+ KB\n"]}],"source":["test_df.info()   # Verificar informaci√≥n de los datos de prueba."]},{"cell_type":"code","execution_count":17,"id":"259f22fd","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718640101907,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"259f22fd"},"outputs":[],"source":["# Convier a listas datos de entrenamiento.\n","train_review = train_df['review'].tolist()\n","train_rating = train_df['rating'].tolist()\n","\n","# Convier a listas datos de prueba.\n","test_review = test_df['review'].tolist()\n","test_rating = test_df['rating'].tolist()"]},{"cell_type":"markdown","id":"548e677e","metadata":{"id":"548e677e"},"source":["#### 3.- Utiliza un modelo Transformer de HuggingFace para an√°lisis de sentimiento en ingl√©s y lleva a cabo la predicci√≥n de los comentarios en los siguientes casos:"]},{"cell_type":"markdown","id":"153dfe80","metadata":{"id":"153dfe80"},"source":["A. Utiliza uno de los modelos Transformer pre-entrenados que consideres adecuado de DistilBERT de Huggingface para an√°lisis de sentimiento y lleva a cabo el entrenamiento y evaluaci√≥n del desempe√±o con exatitud (accuracy) y matriz de confusi√≥n. NOTA: Recuerda obtener el porcentaje de las clases positivas y negativas para tener una idea clara de si el modelo encontrado queda subentrenado."]},{"cell_type":"code","execution_count":18,"id":"58e6b2f9","metadata":{"id":"58e6b2f9"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":19,"id":"4c0ad8f9","metadata":{"id":"4c0ad8f9","outputId":"a10941bc-96a6-4f9d-9ba5-16e409031892"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"]},{"cell_type":"markdown","id":"f6ef0435","metadata":{"id":"f6ef0435"},"source":["Separaci√≥n de nuestro modelo para pruebas y entrenamiento"]},{"cell_type":"code","execution_count":20,"id":"45e03050","metadata":{"id":"45e03050","outputId":"0d6dcb42-22a9-45cd-ea07-3ffee2daf503"},"outputs":[{"data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"code","execution_count":21,"id":"17235732","metadata":{"id":"17235732","scrolled":true},"outputs":[],"source":["def tokenize_function(text):\n","    return tokenizer(text, padding='max_length', truncation=True)\n","\n","train_encodings = tokenizer(train_review, truncation=True, padding=True)\n","test_encodings = tokenizer(test_review, truncation=True, padding=True)"]},{"cell_type":"markdown","id":"58267dc8","metadata":{"id":"58267dc8"},"source":["Convertir a Dataset de PyTorch"]},{"cell_type":"code","execution_count":22,"id":"706227a7","metadata":{"id":"706227a7"},"outputs":[],"source":["import torch\n","\n","class SentimentDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":23,"id":"6328348d","metadata":{"id":"6328348d"},"outputs":[],"source":["train_dataset = SentimentDataset(train_encodings, train_rating)\n","test_dataset = SentimentDataset(test_encodings, test_rating)"]},{"cell_type":"code","execution_count":24,"id":"5239b663","metadata":{"colab":{"referenced_widgets":["4e0a2e1bf23c48318af1cb49cea69702"]},"id":"5239b663","outputId":"ddb30e57-8010-4717-ea30-a37900492d9e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9876999f30db4fa8a5422f90f0b3330a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":25,"id":"acae0e9a","metadata":{"id":"acae0e9a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mitnik/Documents/MNA/NLP/transformers/src/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=2,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_strategy='epoch',\n","    evaluation_strategy='epoch',\n","    load_best_model_at_end=True,\n","    metric_for_best_model='accuracy',\n","    greater_is_better=True,\n",")\n","\n"]},{"cell_type":"code","execution_count":26,"id":"f104546c","metadata":{"id":"f104546c"},"outputs":[],"source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = predictions.argmax(axis=1)\n","    accuracy = accuracy_score(labels, predictions)\n","    cm = confusion_matrix(labels, predictions)\n","    return {\n","        'accuracy': accuracy,\n","        'confusion_matrix': cm.tolist(),\n","    }"]},{"cell_type":"code","execution_count":27,"id":"4ed2146d","metadata":{"id":"4ed2146d"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":31,"id":"77e61632","metadata":{"id":"77e61632","outputId":"2b1bc617-972f-4ba1-9379-4c41fb9acabf","scrolled":false},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"795df891bd52444081ece464ed3e8b39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/438 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 0.5677, 'grad_norm': 1.3778821229934692, 'learning_rate': 4.8858447488584476e-05, 'epoch': 0.05}\n","{'loss': 0.3753, 'grad_norm': 5.888058662414551, 'learning_rate': 4.7716894977168955e-05, 'epoch': 0.09}\n","{'loss': 0.4672, 'grad_norm': 7.475600719451904, 'learning_rate': 4.657534246575342e-05, 'epoch': 0.14}\n","{'loss': 0.3342, 'grad_norm': 5.589459419250488, 'learning_rate': 4.54337899543379e-05, 'epoch': 0.18}\n","{'loss': 0.3621, 'grad_norm': 3.7634124755859375, 'learning_rate': 4.4292237442922375e-05, 'epoch': 0.23}\n","{'loss': 0.2842, 'grad_norm': 5.911366939544678, 'learning_rate': 4.3150684931506855e-05, 'epoch': 0.27}\n","{'loss': 0.3394, 'grad_norm': 10.677961349487305, 'learning_rate': 4.200913242009132e-05, 'epoch': 0.32}\n","{'loss': 0.2378, 'grad_norm': 12.379060745239258, 'learning_rate': 4.08675799086758e-05, 'epoch': 0.37}\n","{'loss': 0.2373, 'grad_norm': 16.38396644592285, 'learning_rate': 3.9726027397260274e-05, 'epoch': 0.41}\n","{'loss': 0.2814, 'grad_norm': 12.749175071716309, 'learning_rate': 3.8584474885844754e-05, 'epoch': 0.46}\n","{'loss': 0.3553, 'grad_norm': 8.585990905761719, 'learning_rate': 3.744292237442922e-05, 'epoch': 0.5}\n","{'loss': 0.2908, 'grad_norm': 8.08005142211914, 'learning_rate': 3.63013698630137e-05, 'epoch': 0.55}\n","{'loss': 0.2961, 'grad_norm': 9.357749938964844, 'learning_rate': 3.5159817351598174e-05, 'epoch': 0.59}\n","{'loss': 0.275, 'grad_norm': 6.37974739074707, 'learning_rate': 3.4018264840182654e-05, 'epoch': 0.64}\n","{'loss': 0.2995, 'grad_norm': 5.7617926597595215, 'learning_rate': 3.287671232876712e-05, 'epoch': 0.68}\n","{'loss': 0.257, 'grad_norm': 4.973231792449951, 'learning_rate': 3.17351598173516e-05, 'epoch': 0.73}\n","{'loss': 0.2067, 'grad_norm': 4.271337032318115, 'learning_rate': 3.059360730593607e-05, 'epoch': 0.78}\n","{'loss': 0.3015, 'grad_norm': 6.924004077911377, 'learning_rate': 2.945205479452055e-05, 'epoch': 0.82}\n","{'loss': 0.276, 'grad_norm': 5.060338020324707, 'learning_rate': 2.8310502283105023e-05, 'epoch': 0.87}\n","{'loss': 0.2069, 'grad_norm': 2.227731704711914, 'learning_rate': 2.71689497716895e-05, 'epoch': 0.91}\n","{'loss': 0.173, 'grad_norm': 2.066312551498413, 'learning_rate': 2.6027397260273973e-05, 'epoch': 0.96}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c56abbaa86ce4e48883056ec90f837af","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/94 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[[304, 48], [87, 1061]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.2692786753177643, 'eval_accuracy': 0.91, 'eval_confusion_matrix': [[304, 48], [87, 1061]], 'eval_runtime': 600.2393, 'eval_samples_per_second': 2.499, 'eval_steps_per_second': 0.157, 'epoch': 1.0}\n","{'loss': 0.1964, 'grad_norm': 6.573577880859375, 'learning_rate': 2.4885844748858446e-05, 'epoch': 1.0}\n","{'loss': 0.2677, 'grad_norm': 14.783027648925781, 'learning_rate': 2.3744292237442922e-05, 'epoch': 1.05}\n","{'loss': 0.1134, 'grad_norm': 0.5544476509094238, 'learning_rate': 2.2602739726027396e-05, 'epoch': 1.1}\n","{'loss': 0.1117, 'grad_norm': 8.859907150268555, 'learning_rate': 2.1461187214611872e-05, 'epoch': 1.14}\n","{'loss': 0.174, 'grad_norm': 13.36316204071045, 'learning_rate': 2.0319634703196345e-05, 'epoch': 1.19}\n","{'loss': 0.047, 'grad_norm': 0.8550947904586792, 'learning_rate': 1.9178082191780822e-05, 'epoch': 1.23}\n","{'loss': 0.2294, 'grad_norm': 1.5666804313659668, 'learning_rate': 1.80365296803653e-05, 'epoch': 1.28}\n","{'loss': 0.0756, 'grad_norm': 9.243277549743652, 'learning_rate': 1.689497716894977e-05, 'epoch': 1.32}\n","{'loss': 0.1626, 'grad_norm': 11.18776798248291, 'learning_rate': 1.5753424657534248e-05, 'epoch': 1.37}\n","{'loss': 0.0778, 'grad_norm': 3.939216375350952, 'learning_rate': 1.4611872146118721e-05, 'epoch': 1.42}\n","{'loss': 0.1464, 'grad_norm': 20.345104217529297, 'learning_rate': 1.3470319634703196e-05, 'epoch': 1.46}\n","{'loss': 0.1969, 'grad_norm': 0.716107964515686, 'learning_rate': 1.2328767123287671e-05, 'epoch': 1.51}\n","{'loss': 0.0832, 'grad_norm': 14.21170425415039, 'learning_rate': 1.1187214611872146e-05, 'epoch': 1.55}\n","{'loss': 0.1002, 'grad_norm': 15.943148612976074, 'learning_rate': 1.004566210045662e-05, 'epoch': 1.6}\n","{'loss': 0.1422, 'grad_norm': 2.3428289890289307, 'learning_rate': 8.904109589041095e-06, 'epoch': 1.64}\n","{'loss': 0.0886, 'grad_norm': 4.548734664916992, 'learning_rate': 7.76255707762557e-06, 'epoch': 1.69}\n","{'loss': 0.1574, 'grad_norm': 7.815217971801758, 'learning_rate': 6.621004566210046e-06, 'epoch': 1.74}\n","{'loss': 0.1638, 'grad_norm': 2.313065528869629, 'learning_rate': 5.479452054794521e-06, 'epoch': 1.78}\n","{'loss': 0.1802, 'grad_norm': 0.1750398576259613, 'learning_rate': 4.337899543378996e-06, 'epoch': 1.83}\n","{'loss': 0.0993, 'grad_norm': 13.551811218261719, 'learning_rate': 3.19634703196347e-06, 'epoch': 1.87}\n","{'loss': 0.235, 'grad_norm': 6.5590620040893555, 'learning_rate': 2.054794520547945e-06, 'epoch': 1.92}\n","{'loss': 0.1533, 'grad_norm': 10.662628173828125, 'learning_rate': 9.132420091324201e-07, 'epoch': 1.96}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13051646fb0442c5ba9b99e3d384fdf2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/94 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[[286, 66], [68, 1080]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.3113105595111847, 'eval_accuracy': 0.9106666666666666, 'eval_confusion_matrix': [[286, 66], [68, 1080]], 'eval_runtime': 580.3399, 'eval_samples_per_second': 2.585, 'eval_steps_per_second': 0.162, 'epoch': 2.0}\n","{'train_runtime': 10317.2427, 'train_samples_per_second': 0.678, 'train_steps_per_second': 0.042, 'train_loss': 0.22048698712701667, 'epoch': 2.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=438, training_loss=0.22048698712701667, metrics={'train_runtime': 10317.2427, 'train_samples_per_second': 0.678, 'train_steps_per_second': 0.042, 'total_flos': 927271790592000.0, 'train_loss': 0.22048698712701667, 'epoch': 2.0})"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":32,"id":"585d5431","metadata":{"id":"585d5431","outputId":"41a89cbb-88e7-46e2-e6b5-cb0b67c94ac1"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02b162c5887c455aae1c047465c170a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/94 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[[286, 66], [68, 1080]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.3113105595111847, 'eval_accuracy': 0.9106666666666666, 'eval_confusion_matrix': [[286, 66], [68, 1080]], 'eval_runtime': 636.66, 'eval_samples_per_second': 2.356, 'eval_steps_per_second': 0.148, 'epoch': 2.0}\n"]}],"source":["# Evaluar el modelo en el conjunto de prueba\n","results = trainer.evaluate(eval_dataset=test_dataset)\n","print(results['eval_confusion_matrix'])"]},{"cell_type":"code","execution_count":38,"id":"7907923e","metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 400x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(4, 3))\n","sns.heatmap(results['eval_confusion_matrix'], annot=True, fmt='d', cmap='Blues', cbar=False, \n","            xticklabels=['Predicted Negative', 'Predicted Positive'], \n","            yticklabels=['Actual Negative', 'Actual Positive'])\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":43,"id":"6c11bcf7","metadata":{},"outputs":[],"source":["trainer.save_model(\"./models/\")"]},{"cell_type":"code","execution_count":33,"id":"0c1e4d9c","metadata":{"id":"0c1e4d9c","outputId":"161c40e2-43e7-414b-bc02-5cf7a0bd2ff5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Exactitud (Accuracy): 0.9106666666666666\n","Matriz de Confusi√≥n:\n","[[286, 66], [68, 1080]]\n"]}],"source":["# Mostrar m√©tricas de evaluaci√≥n\n","print(\"Exactitud (Accuracy):\", results['eval_accuracy'])\n","print(\"Matriz de Confusi√≥n:\")\n","print(results['eval_confusion_matrix'])"]},{"cell_type":"code","execution_count":null,"id":"d9885e71","metadata":{"id":"d9885e71"},"outputs":[],"source":["# Dividir el conjunto de entrenamiento en entrenamiento y validaci√≥n (80% entrenamiento, 20% validaci√≥n)\n","sub_train_review, sub_val_review, sub_train_rating, sub_val_rating = train_test_split(train_review, train_rating, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"24816d03","metadata":{"id":"24816d03","outputId":"acf73ff1-d29d-4491-e6d4-e9f5f2bea2bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tama√±o del conjunto de entrenamiento review: 2800\n","Tama√±o del conjunto de validaci√≥n review: 700\n","Tama√±o del conjunto de entrenamiento rating: 2800\n","Tama√±o del conjunto de validaci√≥n rating: 700\n"]}],"source":["print(f'Tama√±o del conjunto de entrenamiento review: {len(sub_train_review)}')\n","print(f'Tama√±o del conjunto de validaci√≥n review: {len(sub_val_review)}')\n","\n","print(f'Tama√±o del conjunto de entrenamiento rating: {len(sub_train_rating)}')\n","print(f'Tama√±o del conjunto de validaci√≥n rating: {len(sub_val_rating)}')"]},{"cell_type":"code","execution_count":null,"id":"1910b86a","metadata":{"id":"1910b86a"},"outputs":[],"source":["train_encodings = tokenizer(sub_train_review, truncation=True, padding=True)\n","val_encodings = tokenizer(sub_val_review, truncation=True, padding=True)\n","test_encodings = tokenizer(test_review, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"id":"6131f57f","metadata":{"id":"6131f57f"},"outputs":[],"source":["train_dataset = SentimentDataset(train_encodings, sub_train_rating)\n","val_dataset = SentimentDataset(val_encodings, sub_val_rating)\n","test_dataset = SentimentDataset(test_encodings, test_rating)"]},{"cell_type":"markdown","id":"ff607b3f","metadata":{"id":"ff607b3f"},"source":["Se carga el modelo pre-entrenado"]},{"cell_type":"code","execution_count":null,"id":"0a6eb94d","metadata":{"id":"0a6eb94d","outputId":"7bfbc94b-de38-4eb3-a1b2-f10e4851371b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"]},{"cell_type":"code","execution_count":null,"id":"acbdd944","metadata":{"id":"acbdd944"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mitnik/.local/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n","2024-06-17 12:37:43.389210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-17 12:37:43.389248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-17 12:37:43.390635: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-17 12:37:44.930134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"ename":"RuntimeError","evalue":"Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1557\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/usr/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n","\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1557\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/usr/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/integrations/integration_utils.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n","File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1547\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1547\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1559\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configurar argumentos de entrenamiento\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./sub-results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./sub-logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m<string>:129\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start)\u001b[0m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/training_args.py:1759\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_to \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_to \u001b[38;5;241m==\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# Import at runtime to avoid a circular import.\u001b[39;00m\n\u001b[0;32m-> 1759\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_available_reporting_integrations\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_to \u001b[38;5;241m=\u001b[39m get_available_reporting_integrations()\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodecarbon\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport_to \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mhip:\n","File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1547\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1547\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1548\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1559\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."]}],"source":["# Configurar argumentos de entrenamiento\n","training_args = TrainingArguments(\n","    output_dir='./sub-results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    logging_dir='./sub-logs',\n","    logging_steps=10,\n","    save_strategy='epoch',\n","    eval_strategy='epoch',\n","    load_best_model_at_end=True,\n","    metric_for_best_model='loss',\n","    greater_is_better=False,\n",")"]},{"cell_type":"code","execution_count":null,"id":"57edd824","metadata":{"id":"57edd824"},"outputs":[{"ename":"NameError","evalue":"name 'Trainer' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      4\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m      5\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m      6\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      7\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"id":"9a11f468","metadata":{"id":"9a11f468","outputId":"e65d0581-2416-446a-e779-a5bea9496791"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [525/525 1:57:53, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.258800</td>\n","      <td>0.259694</td>\n","      <td>0.882857</td>\n","      <td>[[146, 19], [63, 472]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.199500</td>\n","      <td>0.348668</td>\n","      <td>0.905714</td>\n","      <td>[[117, 48], [18, 517]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.106100</td>\n","      <td>0.378402</td>\n","      <td>0.905714</td>\n","      <td>[[128, 37], [29, 506]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[[146, 19], [63, 472]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[[117, 48], [18, 517]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[[128, 37], [29, 506]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"text/plain":["TrainOutput(global_step=525, training_loss=0.1730094559206849, metrics={'train_runtime': 7084.4111, 'train_samples_per_second': 1.186, 'train_steps_per_second': 0.074, 'total_flos': 1112726148710400.0, 'train_loss': 0.1730094559206849, 'epoch': 3.0})"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["# Entrenar el modelo\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"085c2f6c","metadata":{"id":"085c2f6c","outputId":"004fabb4-fb59-4155-e414-b13e822c1d55"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [94/94 02:56]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"[[311, 41], [150, 998]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.293605774641037, 'eval_accuracy': 0.8726666666666667, 'eval_confusion_matrix': [[311, 41], [150, 998]], 'eval_runtime': 178.4308, 'eval_samples_per_second': 8.407, 'eval_steps_per_second': 0.527, 'epoch': 3.0}\n"]}],"source":["# Evaluar el modelo en el conjunto de prueba\n","results = trainer.evaluate(eval_dataset=test_dataset)\n","print(results)"]},{"cell_type":"code","execution_count":null,"id":"09de8e27","metadata":{},"outputs":[],"source":["plt.figure(figsize=(8, 6))\n","sns.heatmap(results['eval_confusion_matrix'], annot=True, fmt='d', cmap='Blues', cbar=False, \n","            xticklabels=['Predicted Negative', 'Predicted Positive'], \n","            yticklabels=['Actual Negative', 'Actual Positive'])\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ad0d02b1","metadata":{"id":"ad0d02b1"},"outputs":[],"source":["# Mostrar m√©tricas de evaluaci√≥n\n","print(\"Exactitud (Accuracy):\", results['eval_accuracy'])\n","print(\"Matriz de Confusi√≥n:\")\n","print(results['eval_confusion_matrix'])"]},{"cell_type":"markdown","id":"fAlQsGhmBcVI","metadata":{"id":"fAlQsGhmBcVI"},"source":["#### 4.- Utiliza un modelo Transformer de HuggingFace para an√°lisis de sentimiento en ingl√©s y lleva a cabo la predicci√≥n de los comentarios en los siguientes casos:"]},{"cell_type":"markdown","id":"vVde2TCSBl_5","metadata":{"id":"vVde2TCSBl_5"},"source":["##### 4a. Utiliza el modelo Tansformer pre-entrenado para traducci√≥n de ingl√©s a espa√±ol llamado Helsinki-NLP/opus-mt-en-es de Huggingface y traduce los 10 comentarios que seleccionaste.\n"]},{"cell_type":"code","execution_count":54,"id":"B6CZuuj8Bz-x","metadata":{"id":"B6CZuuj8Bz-x"},"outputs":[],"source":["df_sample = df.sample(n=10)     # Seleccionar 10 registros aleatorios."]},{"cell_type":"code","execution_count":65,"id":"QUmbSxdWB9Yz","metadata":{"id":"QUmbSxdWB9Yz"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23ec23a7b224499f93b74de98ad10086","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60c179b33dd0457c8926a26b7acdffd6","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9a14b6b43d14fa6b3fc8273d6d1759e","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ImportError","evalue":"\nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[65], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar el modelo y tokenizador.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MarianMTModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-en-es\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMarianTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-en-es\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1497\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1497\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/utils/import_utils.py:1485\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1483\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n","\u001b[0;31mImportError\u001b[0m: \nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"]}],"source":["from transformers import MarianMTModel, MarianTokenizer\n","\n","# Cargar el modelo y tokenizador.\n","model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-es')\n","tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es')"]},{"cell_type":"code","execution_count":66,"id":"NzXhUHT3CVgX","metadata":{"id":"NzXhUHT3CVgX"},"outputs":[],"source":["# Funci√≥n para traducir texto.\n","def translate_text(texts):\n","\n","    translated_texts = []\n","\n","    for text in texts:\n","        inputs = tokenizer.encode(text, return_tensors='pt', padding=True, truncation=True)\n","        translated = model.generate(inputs)\n","        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n","        translated_texts.append(translated_text)\n","\n","    return translated_texts"]},{"cell_type":"code","execution_count":67,"id":"fN3vrHTFHE_0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51152,"status":"ok","timestamp":1718610285053,"user":{"displayName":"Miguel Angel Marines Olvera","userId":"15879303690487823760"},"user_tz":360},"id":"fN3vrHTFHE_0","outputId":"710e33f9-da41-412a-ce15-f3be69a2e29f"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m comments \u001b[38;5;241m=\u001b[39m df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Traducir los comentarios\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m translated_comments \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Crear un nuevo DataFrame con los comentarios traducidos.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df_sample_es \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_es\u001b[39m\u001b[38;5;124m'\u001b[39m: translated_comments,  \u001b[38;5;66;03m# Agregar los comentarios traducidos.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m: df_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Mantener la columna original de 'rating'.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m })\n","Cell \u001b[0;32mIn[66], line 8\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m      7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     translated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     translated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(translated[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     translated_texts\u001b[38;5;241m.\u001b[39mappend(translated_text)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/generation/utils.py:1933\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1926\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1927\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1928\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1933\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1947\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1948\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1955\u001b[0m     )\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/generation/utils.py:2894\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2891\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[1;32m   2893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 2894\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2902\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/models/marian/modeling_marian.py:1399\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1396\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1397\u001b[0m         )\n\u001b[0;32m-> 1399\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1418\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/models/marian/modeling_marian.py:1194\u001b[0m, in \u001b[0;36mMarianModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1188\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1189\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1190\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m     )\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/models/marian/modeling_marian.py:994\u001b[0m, in \u001b[0;36mMarianDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    981\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    982\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    983\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m         use_cache,\n\u001b[1;32m    992\u001b[0m     )\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 994\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/models/marian/modeling_marian.py:404\u001b[0m, in \u001b[0;36mMarianDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    402\u001b[0m self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    412\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Documents/MNA/NLP/transformers/src/transformers/models/marian/modeling_marian.py:181\u001b[0m, in \u001b[0;36mMarianAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    179\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[1;32m    180\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[0;32m--> 181\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m1\u001b[39m], value_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# self_attention\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Extraer los comentarios seleccionados.\n","comments = df_sample['review'].tolist()\n","\n","# Traducir los comentarios\n","translated_comments = translate_text(comments)\n","\n","# Crear un nuevo DataFrame con los comentarios traducidos.\n","df_sample_es = pd.DataFrame({\n","    'text_es': translated_comments,  # Agregar los comentarios traducidos.\n","    'rating': df_sample['rating']  # Mantener la columna original de 'rating'.\n","})\n","\n","# Texto original en ingles y texto traducido al espa√±ol.\n","print('Texto Original en Ingl√©s:')\n","print(df_sample)\n","print()\n","print('Texto Traducido al Espa√±ol:')\n","print(df_sample_es)"]},{"cell_type":"markdown","id":"d1b2a63d","metadata":{},"source":["### 4b Utiliza ahora el LLM Gemini de Google a trav√©s de su API para traducir los mismos 10\n","comentarios del inciso anterior. NOTA: deber√°s proponer el prompt que consideres\n","adecuado para la traducci√≥n, incluyendo si consideras que ayuda, que tome en cuenta\n","errores tipogr√°ficos (typos), o alg√∫n otro tipo de consideraci√≥n.\n","NOTA: Puedes consultar la siguiente liga para familiarizarte con la API de Gemini:\n","https://ai.google.dev/gemini-api/docs/get-started/tutorial?hl=es-419&lang=python "]},{"cell_type":"code","execution_count":44,"id":"5507deae","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/wifiphisher-1.4-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/fasttext-0.9.2-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["!pip install -q -U google-generativeai"]},{"cell_type":"code","execution_count":46,"id":"76206239","metadata":{},"outputs":[],"source":["import pathlib\n","import textwrap\n","\n","import google.generativeai as genai\n","\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","def to_markdown(text):\n","  text = text.replace('‚Ä¢', '  *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"]},{"cell_type":"code","execution_count":47,"id":"bcf8b0a8","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["# from google.colab import userdata"]},{"cell_type":"code","execution_count":69,"id":"91f4f765","metadata":{},"outputs":[],"source":["# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n","GOOGLE_API_KEY=\"AIzaSyB_8qxnC2EZtxltfEHAVrUcODPrxUiyFFU\"\n","\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"code","execution_count":70,"id":"ed86a989","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["models/gemini-1.0-pro\n","models/gemini-1.0-pro-001\n","models/gemini-1.0-pro-latest\n","models/gemini-1.0-pro-vision-latest\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-001\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-pro\n","models/gemini-1.5-pro-001\n","models/gemini-1.5-pro-latest\n","models/gemini-pro\n","models/gemini-pro-vision\n"]}],"source":["for m in genai.list_models():\n","  if 'generateContent' in m.supported_generation_methods:\n","    print(m.name)"]},{"cell_type":"code","execution_count":71,"id":"29e37214","metadata":{},"outputs":[],"source":["model = genai.GenerativeModel('gemini-1.5-flash')"]},{"cell_type":"code","execution_count":86,"id":"882a69d6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["##\n"," Palabras clave para SEO de ferreter√≠a:\n","\n","**General:**\n","\n","*\n"," Ferreter√≠a\n","* Tienda de herramientas\n","* Materiales de construcci√≥n\n","*\n"," Suministros para el hogar\n","* Bricolaje\n","* Reparaci√≥n\n","* Construcci√≥n\n","* Remodelaci√≥n\n","* Jard√≠n\n","* Pintura\n","\n","**\n","Categor√≠as espec√≠ficas:**\n","\n","* **Herramientas:** martillo, destornillador, taladro, sierra, llave inglesa, alicates, cinta m√©trica\n",", nivel, lijadora, soldador\n","* **Materiales de construcci√≥n:** madera, metal, cemento, ladrillo, tejas, pintura, yeso, yeso para juntas, tuber√≠as, alambre\n","* **Suministros para\n"," el hogar:** bombillas, interruptores, enchufes, tornillos, clavos, pegamento, cinta adhesiva, abrazaderas, mangueras, filtros de agua\n","* **Jard√≠n:** herramientas de jard√≠n, semillas, fertilizantes\n",", pesticidas, macetas, mangueras de jard√≠n, aspersores\n","* **Seguridad:** candados, cerraduras, alarmas, c√°maras de seguridad, detectores de humo, extintores de incendios\n","* **Iluminaci√≥n:** bombillas LED, focos, l√°mparas, tiras LED,\n"," proyectores\n","* **Electricidad:** cables, enchufes, interruptores, cajas de conexiones, fusibles\n","* **Plomer√≠a:** tuber√≠as, grifos, inodoros, duchas, lavabos, v√°lvulas, sifones\n","* **Carpinter√≠a:** madera, herramientas de carpinter√≠a,\n"," tornillos, clavos, pegamento, lijadoras, sierras\n","\n","**Combinaciones:**\n","\n","* Ferreter√≠a online\n","* Ferreter√≠a cerca de m√≠\n","* Ferreter√≠a 24 horas\n","* Ferreter√≠a precios\n","* Ferreter√≠a ofertas\n","* Ferreter√≠a env√≠o gratis\n","* Herramientas de\n"," mano para bricolaje\n","* Materiales de construcci√≥n para reforma\n","* Suministros de jardiner√≠a online\n","\n","**Localizaci√≥n:**\n","\n","* [Nombre de la ciudad] ferreter√≠a\n","* [Nombre de la ciudad] tienda de herramientas\n","* Ferreter√≠a en [Nombre del barrio]\n","* Ferreter√≠a\n"," [Nombre de la provincia]\n","\n","**Consejos adicionales:**\n","\n","* **Investigaci√≥n de palabras clave:** Utiliza herramientas como Google Keyword Planner, Ahrefs o SEMrush para encontrar palabras clave relevantes y con volumen de b√∫squeda.\n","* **Palabras clave de cola larga:** Son frases m√°s espec√≠ficas que suelen tener menor competencia y mayor\n"," conversi√≥n. Por ejemplo, \"ferreter√≠a online herramientas de jard√≠n\".\n","* **Optimiza el contenido de tu sitio web:**  Usa las palabras clave en los t√≠tulos, descripciones, encabezados, textos e im√°genes de tu sitio web.\n","* **Crea contenido de calidad:** Publica art√≠culos de blog, gu√≠as\n",", v√≠deos y otros contenidos que sean √∫tiles para tus clientes potenciales.\n","\n","Recuerda que este es solo un punto de partida. Investiga las palabras clave espec√≠ficas de tu nicho de mercado y optimiza tu sitio web para atraer a los clientes adecuados.\n"]}],"source":["#prompt = f\"Generar el copy de 300 caracteres en una sola oracion para seccion banner de la landing de una ferreteria\"\n","prompt = f\"Generar el copy de 300 caracteres en una sola oracion para seccion banner de la landing de una ferreteria\"\n","response = model.generate_content(prompt, stream=True)\n","\n","for chunk in response:\n","  print(chunk.text)\n","  "]},{"cell_type":"code","execution_count":52,"id":"fe39f73f","metadata":{},"outputs":[{"data":{"text/plain":["response:\n","GenerateContentResponse(\n","    done=True,\n","    iterator=None,\n","    result=protos.GenerateContentResponse({\n","      \"candidates\": [\n","        {\n","          \"content\": {\n","            \"parts\": [\n","              {\n","                \"text\": \"As a large language model, I am not capable of providing a definitive answer to the question of the meaning of life. This is a deeply philosophical question that has been debated by thinkers for centuries, and there is no single, universally accepted answer. \\n\\nHowever, I can offer some perspectives that might help you explore this question for yourself:\\n\\n* **Existentialism:** This philosophy emphasizes individual freedom and responsibility, suggesting that we create our own meaning through our choices and actions.\\n* **Nihilism:** This view suggests that life is ultimately meaningless and there is no inherent purpose. \\n* **Religion and Spirituality:** Many religions offer a framework for understanding life's purpose, often centered around a higher power or divine plan.\\n* **Humanism:** This philosophy focuses on human values and potential, emphasizing the importance of reason, compassion, and the pursuit of happiness.\\n* **Hedonism:** This view suggests that the purpose of life is to maximize pleasure and minimize pain.\\n* **Stoicism:** This philosophy emphasizes accepting what we cannot control and focusing on what is within our power, such as our thoughts and actions.\\n\\nUltimately, the meaning of life is a personal question. It is up to each individual to determine what gives their life purpose and value. Some may find meaning in relationships, work, creativity, or service to others. Others may find it in personal growth, exploring the world, or simply enjoying the present moment.\\n\\nHere are some questions that might help you explore this question for yourself:\\n\\n* What brings you joy and fulfillment?\\n* What are your values and beliefs?\\n* What do you want to leave behind as your legacy?\\n* What kind of impact do you want to have on the world?\\n\\nThere is no right or wrong answer to the question of the meaning of life. The journey of exploring this question is itself a part of what gives life meaning. \\n\"\n","              }\n","            ],\n","            \"role\": \"model\"\n","          },\n","          \"finish_reason\": \"STOP\",\n","          \"index\": 0,\n","          \"safety_ratings\": [\n","            {\n","              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            },\n","            {\n","              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n","              \"probability\": \"NEGLIGIBLE\"\n","            }\n","          ]\n","        }\n","      ],\n","      \"usage_metadata\": {\n","        \"prompt_token_count\": 7,\n","        \"candidates_token_count\": 387,\n","        \"total_token_count\": 394\n","      }\n","    }),\n",")"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["response"]}],"metadata":{"colab":{"collapsed_sections":["7ee4e86b","3b724e16"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
